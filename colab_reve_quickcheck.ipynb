{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AdaBrain-Bench Colab Quick Check (EEGNet + REVE)\n",
        "\n",
        "This notebook pulls the repo, creates a tiny synthetic dataset, runs a quick EEGNet sanity check, and then runs REVE in dry-run mode on the same sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/iroblesrazzaq/AdaBrain-Bench.git\n",
        "%cd AdaBrain-Bench\n",
        "!pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd295acf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "if sys.version_info >= (3, 12):\n",
        "    subprocess.check_call([\n",
        "        sys.executable, '-m', 'pip', 'install', '-q', '--upgrade', '--force-reinstall',\n",
        "        'numpy>=2.0', 'scipy>=1.11'\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "root = Path('synthetic_data/SEED/multi_subject_json')\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "C = 4\n",
        "T = 200\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "def make_samples(n, tag):\n",
        "    samples = []\n",
        "    for i in range(n):\n",
        "        x = rng.standard_normal((C, T)).astype(np.float32)\n",
        "        y = float(i % 2)\n",
        "        path = root / f'{tag}_sample_{i}.pkl'\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump({'X': x, 'Y': y}, f)\n",
        "        samples.append({'file': str(path), 'label': int(y), 'subject_id': 0})\n",
        "    return samples\n",
        "\n",
        "train = make_samples(12, 'train')\n",
        "val = make_samples(4, 'val')\n",
        "test = make_samples(4, 'test')\n",
        "\n",
        "all_samples = train + val + test\n",
        "stack = np.stack([pickle.load(open(s['file'], 'rb'))['X'] for s in all_samples], axis=0)\n",
        "mean = stack.mean(axis=(0, 2)).tolist()\n",
        "std = stack.std(axis=(0, 2)).tolist()\n",
        "minv = stack.min(axis=(0, 2)).tolist()\n",
        "maxv = stack.max(axis=(0, 2)).tolist()\n",
        "\n",
        "dataset_info = {\n",
        "    'sampling_rate': 200,\n",
        "    'ch_names': [f'Ch{i + 1}' for i in range(C)],\n",
        "    'mean': mean,\n",
        "    'std': std,\n",
        "    'min': minv,\n",
        "    'max': maxv,\n",
        "}\n",
        "\n",
        "def write_split(name, data):\n",
        "    payload = {'dataset_info': dataset_info, 'subject_data': data}\n",
        "    with open(root / f'{name}.json', 'w') as f:\n",
        "        json.dump(payload, f)\n",
        "\n",
        "write_split('train', train)\n",
        "write_split('val', val)\n",
        "write_split('test', test)\n",
        "\n",
        "config_path = Path('dataset_config/Classification.json')\n",
        "if config_path.exists():\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "else:\n",
        "    config = {}\n",
        "\n",
        "config['SEED'] = {\n",
        "    'root': {'multi': str(root), 'cross': str(root), 'fewshot': str(root)},\n",
        "    'num_classes': 2,\n",
        "    'num_t': 1,\n",
        "}\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print('Synthetic dataset ready at', root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python run_finetuning.py --model_name EEGNet --dataset SEED --task_mod Classification --subject_mod cross --finetune_mod full --norm_method z_score --batch_size 4 --epochs 1 --lr 1e-3 --sampling_rate 200 --seed 0 --num_workers 0 --device cpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## REVE dry-run\n",
        "If the model is gated for your account, authenticate once with `huggingface-cli login`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional login if access is gated\n",
        "# !huggingface-cli login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python run_finetuning.py --model_name REVE --dataset SEED --task_mod Classification --subject_mod cross --finetune_mod full --norm_method z_score --batch_size 4 --epochs 1 --lr 1e-3 --sampling_rate 200 --seed 0 --num_workers 0 --device cpu --dry_run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -la finetuning_results/Classification || true\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
